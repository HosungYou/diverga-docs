'use client';

import { useLocale } from 'next-intl';
import Link from 'next/link';
import { motion } from 'framer-motion';
import {
  ArrowLeft,
  Users,
  MessageSquare,
  Eye,
  ClipboardList,
  AlertCircle,
  CheckCircle2,
  Clock,
} from 'lucide-react';

const content = {
  en: {
    back: 'Back to Agents',
    title: 'Category D: Data Collection Agents',
    subtitle: 'Comprehensive data collection strategy and instrument development',
    description: 'Data Collection agents provide structured guidance for sampling, interviews, observations, and measurement. They adapt protocols to your research paradigm while maintaining methodological rigor.',

    // Core principle
    principleTitle: 'Core Principle',
    principleText: 'Structured but adaptive protocols across quantitative, qualitative, and mixed paradigms',

    // Agents
    agents: [
      {
        id: 'D1',
        name: 'Sampling Strategy Advisor',
        icon: 'users',
        color: '#9b59b6',
        model: 'Sonnet',
        tier: 'MEDIUM',
        checkpoint: 'None',
        checkpointLevel: 'Advisory',
        vsLevel: 'Light VS (Modal awareness)',
        purpose: 'Design probability and non-probability sampling strategies with sample size justification',
        triggers: {
          en: ['sampling', 'sample size', 'participant recruitment', 'G*Power', 'power analysis'],
          ko: ['ÌëúÏßë', 'ÌëúÎ≥∏ ÌÅ¨Í∏∞', 'ÏÉòÌîåÎßÅ', 'Ï∞∏Í∞ÄÏûê Î™®Ïßë', 'Í≤ÄÏ†ïÎ†•'],
        },
        capabilities: [
          'Probability sampling (simple random, stratified, cluster, systematic)',
          'Non-probability sampling (convenience, purposive, snowball, quota)',
          'Theoretical sampling for grounded theory',
          'Sample size calculation (G*Power, saturation assessment)',
          'Recruitment strategy design',
        ],
        vsProcess: 'Identifies modal sampling approaches, presents alternatives with rationale',
        example: {
          input: '"Need 200 participants for survey study"',
          output: 'Direction A (T‚âà0.6): Stratified random sampling by institution type | Direction B (T‚âà0.4): Two-stage cluster sampling (schools ‚Üí students) | Direction C (T<0.3): Adaptive sampling with network referrals',
        },
      },
      {
        id: 'D2',
        name: 'Interview & Focus Group Specialist',
        icon: 'messageSquare',
        color: '#8e44ad',
        model: 'Sonnet',
        tier: 'MEDIUM',
        checkpoint: 'None',
        checkpointLevel: 'Advisory',
        vsLevel: 'Light VS (Modal awareness)',
        purpose: 'Develop interview protocols, probing strategies, and transcription guidance',
        triggers: {
          en: ['interview', 'focus group', 'interview protocol', 'semi-structured', 'probing'],
          ko: ['Ïù∏ÌÑ∞Î∑∞', 'Î©¥Îã¥', 'Ìè¨Ïª§Ïä§ Í∑∏Î£π', 'Î∞òÍµ¨Ï°∞Ìôî', 'Ïã¨Ï∏µÎ©¥Îã¥'],
        },
        capabilities: [
          'Interview protocol development (structured, semi-structured, unstructured)',
          'Focus group moderation guides',
          'Probing and follow-up question strategies',
          'Transcription protocols (verbatim, intelligent verbatim)',
          'Member checking procedures',
        ],
        vsProcess: 'Suggests protocol variations based on paradigm (phenomenology, grounded theory, etc.)',
        example: {
          input: '"Interview protocol for teacher AI experiences"',
          output: 'Opening: "Tell me about your first encounter with AI tools" | Main: "Describe a moment when AI changed your teaching practice" | Probing: "What did that feel like?" "What happened next?" | Closing: "What haven\'t I asked that you think is important?"',
        },
      },
      {
        id: 'D3',
        name: 'Observation Protocol Designer',
        icon: 'eye',
        color: '#7d3c98',
        model: 'Haiku',
        tier: 'LOW',
        checkpoint: 'None',
        checkpointLevel: 'Advisory',
        vsLevel: 'None',
        purpose: 'Design structured observation protocols, field notes, and video analysis coding schemes',
        triggers: {
          en: ['observation', 'field notes', 'participant observation', 'video analysis', 'ethnography'],
          ko: ['Í¥ÄÏ∞∞', 'ÌòÑÏû•ÎÖ∏Ìä∏', 'Ï∞∏Ïó¨Í¥ÄÏ∞∞', 'ÎπÑÎîîÏò§ Î∂ÑÏÑù', 'ÎØºÏ°±ÏßÄ'],
        },
        capabilities: [
          'Structured observation protocols with coding schemes',
          'Field note templates (descriptive, reflective, analytic)',
          'Video analysis frameworks (interaction analysis, conversation analysis)',
          'Observer training procedures',
          'Inter-rater reliability protocols',
        ],
        vsProcess: 'Direct protocol generation based on research context',
        example: {
          input: '"Observe classroom AI tool usage"',
          output: 'Time sampling: 5-min intervals | Categories: Tool type, Task type, Student engagement, Teacher support | Field notes: Descriptive (what happened), Reflective (observer thoughts), Analytic (patterns, themes)',
        },
      },
      {
        id: 'D4',
        name: 'Measurement Instrument Developer',
        icon: 'clipboardList',
        color: '#6c3483',
        model: 'Opus',
        tier: 'HIGH',
        checkpoint: 'CP_METHODOLOGY_APPROVAL',
        checkpointLevel: 'REQUIRED',
        vsLevel: 'Enhanced VS 3-Phase',
        purpose: 'Construct scales, validate instruments, and provide reliability/validity evidence',
        triggers: {
          en: ['instrument', 'scale development', 'measurement', 'validity', 'reliability', 'Likert scale'],
          ko: ['Ï∏°Ï†ïÎèÑÍµ¨', 'Ï≤ôÎèÑ Í∞úÎ∞ú', 'ÎèÑÍµ¨ ÌÉÄÎãπÌôî', 'Ïã†Î¢∞ÎèÑ', 'ÌÉÄÎãπÎèÑ', 'Î¶¨Ïª§Ìä∏'],
        },
        capabilities: [
          'Scale construction (item generation, response formats)',
          'Content validity (expert review, CVI calculation)',
          'Construct validity (EFA, CFA, known-groups)',
          'Reliability testing (Cronbach\'s Œ±, test-retest, inter-rater)',
          'Measurement invariance testing',
        ],
        vsProcess: 'Stage 1: Identify modal scales | Stage 2: Present adaptation vs. new scale options | Stage 3: Human decision',
        example: {
          input: '"Measure AI self-efficacy in teachers"',
          output: 'üî¥ CHECKPOINT: CP_METHODOLOGY_APPROVAL | Option A: Adapt Computer Self-Efficacy Scale | Option B: New AI-Teaching Self-Efficacy Scale (5 dimensions: Technical, Pedagogical, Ethical, Assessment, Professional) | Validation: Content (10 experts), Construct (EFA‚ÜíCFA), Reliability (Œ±, test-retest)',
        },
      },
    ],

    // Additional sections
    paradigmCoverage: 'Paradigm Coverage',
    paradigmText: 'Quantitative (D1, D4), Qualitative (D2, D3), Mixed (all agents adapt)',

    integrationTitle: 'Integration with Other Categories',
    integrationPoints: [
      'Category C (Design): D1 informed by C1/C2/C3 research design',
      'Category E (Analysis): D4 validity evidence feeds E1 statistical analysis',
      'Category F (Quality): D2/D3 protocols reviewed by F4 for trustworthiness',
      'Category A (Foundation): D4 instrument alignment with A2 theoretical framework',
    ],

    checkpointInfo: 'Checkpoint Information',
    checkpointText: 'D4 (Measurement Instrument Developer) requires CP_METHODOLOGY_APPROVAL (üî¥ REQUIRED) before scale construction to ensure alignment with research design and theoretical framework.',

    bestPractices: 'Best Practices',
    practices: [
      'Sample size justification: Always provide power analysis (quant) or saturation rationale (qual)',
      'Protocol pilot testing: Test interview/observation protocols with 2-3 participants before full data collection',
      'Instrument validation: Minimum evidence = content validity + internal consistency',
      'Ethical considerations: All protocols reviewed by D1-D4 must address informed consent, privacy, and data security',
    ],

    autoTrigger: 'Auto-Trigger Examples',
    autoTriggerExamples: [
      {
        userInput: '"I need to interview 20 teachers about AI adoption"',
        detected: 'Keywords: "interview", "20 teachers" ‚Üí Triggers D2 (Interview Specialist) + D1 (Sampling)',
        execution: 'D2 develops semi-structured protocol ‚Üí D1 suggests purposive sampling strategy',
      },
      {
        userInput: '"Create a scale to measure student motivation in AI-assisted learning"',
        detected: 'Keywords: "scale", "measure" ‚Üí Triggers D4 (Instrument Developer)',
        execution: 'üî¥ CP_METHODOLOGY_APPROVAL ‚Üí D4 presents: Adapt existing (AMS) vs. New scale ‚Üí Human decision',
      },
    ],
  },
  ko: {
    back: 'ÏóêÏù¥Ï†ÑÌä∏Î°ú ÎèåÏïÑÍ∞ÄÍ∏∞',
    title: 'Ïπ¥ÌÖåÍ≥†Î¶¨ D: ÏûêÎ£å ÏàòÏßë ÏóêÏù¥Ï†ÑÌä∏',
    subtitle: 'Ìè¨Í¥ÑÏ†Å ÏûêÎ£å ÏàòÏßë Ï†ÑÎûµ Î∞è Ï∏°Ï†ïÎèÑÍµ¨ Í∞úÎ∞ú',
    description: 'ÏûêÎ£å ÏàòÏßë ÏóêÏù¥Ï†ÑÌä∏Îäî ÌëúÏßë, Î©¥Îã¥, Í¥ÄÏ∞∞, Ï∏°Ï†ïÏóê ÎåÄÌïú Íµ¨Ï°∞ÌôîÎêú Í∞ÄÏù¥ÎìúÎ•º Ï†úÍ≥µÌï©ÎãàÎã§. Î∞©Î≤ïÎ°†Ï†Å ÏóÑÍ≤©ÏÑ±ÏùÑ Ïú†ÏßÄÌïòÎ©¥ÏÑú Ïó∞Íµ¨ Ìå®Îü¨Îã§ÏûÑÏóê ÎßûÍ≤å ÌîÑÎ°úÌÜ†ÏΩúÏùÑ Ï°∞Ï†ïÌï©ÎãàÎã§.',

    principleTitle: 'ÌïµÏã¨ ÏõêÏπô',
    principleText: 'ÏñëÏ†Å, ÏßàÏ†Å, ÌòºÌï© Ìå®Îü¨Îã§ÏûÑ Ï†ÑÎ∞òÏóê Í±∏Ïπú Íµ¨Ï°∞ÌôîÎêòÍ≥† Ï†ÅÏùëÏ†ÅÏù∏ ÌîÑÎ°úÌÜ†ÏΩú',

    agents: [
      {
        id: 'D1',
        name: 'ÌëúÏßë Ï†ÑÎûµ ÏûêÎ¨∏',
        icon: 'users',
        color: '#9b59b6',
        model: 'Sonnet',
        tier: 'MEDIUM',
        checkpoint: 'None',
        checkpointLevel: 'Advisory',
        vsLevel: 'Light VS (Î™®Îã¨ Ïù∏Ïãù)',
        purpose: 'ÌëúÎ≥∏ ÌÅ¨Í∏∞ Ï†ïÎãπÌôîÏôÄ Ìï®Íªò ÌôïÎ•† Î∞è ÎπÑÌôïÎ•† ÌëúÏßë Ï†ÑÎûµ ÏÑ§Í≥Ñ',
        triggers: {
          en: ['sampling', 'sample size', 'participant recruitment', 'G*Power', 'power analysis'],
          ko: ['ÌëúÏßë', 'ÌëúÎ≥∏ ÌÅ¨Í∏∞', 'ÏÉòÌîåÎßÅ', 'Ï∞∏Í∞ÄÏûê Î™®Ïßë', 'Í≤ÄÏ†ïÎ†•'],
        },
        capabilities: [
          'ÌôïÎ•† ÌëúÏßë (Îã®ÏàúÎ¨¥ÏÑ†, Ï∏µÌôî, Íµ∞Ïßë, Ï≤¥Í≥ÑÏ†Å)',
          'ÎπÑÌôïÎ•† ÌëúÏßë (Ìé∏Ïùò, Î™©Ï†ÅÏ†Å, ÎààÎç©Ïù¥, Ìï†Îãπ)',
          'Í∑ºÍ±∞Ïù¥Î°†ÏùÑ ÏúÑÌïú Ïù¥Î°†Ï†Å ÌëúÏßë',
          'ÌëúÎ≥∏ ÌÅ¨Í∏∞ Í≥ÑÏÇ∞ (G*Power, Ìè¨ÌôîÎèÑ ÌèâÍ∞Ä)',
          'Î™®Ïßë Ï†ÑÎûµ ÏÑ§Í≥Ñ',
        ],
        vsProcess: 'Î™®Îã¨ ÌëúÏßë Ï†ëÍ∑ºÎ≤ïÏùÑ ÏãùÎ≥ÑÌïòÍ≥† Í∑ºÍ±∞ÏôÄ Ìï®Íªò ÎåÄÏïà Ï†úÏãú',
        example: {
          input: '"ÏÑ§Î¨∏ Ïó∞Íµ¨Î•º ÏúÑÌï¥ 200Î™ÖÏùò Ï∞∏Í∞ÄÏûêÍ∞Ä ÌïÑÏöîÌï¥Ïöî"',
          output: 'Î∞©Ìñ• A (T‚âà0.6): Í∏∞Í¥Ä Ïú†ÌòïÎ≥Ñ Ï∏µÌôî Î¨¥ÏÑ† ÌëúÏßë | Î∞©Ìñ• B (T‚âà0.4): 2Îã®Í≥Ñ Íµ∞Ïßë ÌëúÏßë (ÌïôÍµê ‚Üí ÌïôÏÉù) | Î∞©Ìñ• C (T<0.3): ÎÑ§Ìä∏ÏõåÌÅ¨ Ï∂îÏ≤úÏùÑ ÌôúÏö©Ìïú Ï†ÅÏùëÏ†Å ÌëúÏßë',
        },
      },
      {
        id: 'D2',
        name: 'Î©¥Îã¥ Î∞è Ìè¨Ïª§Ïä§ Í∑∏Î£π Ï†ÑÎ¨∏Í∞Ä',
        icon: 'messageSquare',
        color: '#8e44ad',
        model: 'Sonnet',
        tier: 'MEDIUM',
        checkpoint: 'None',
        checkpointLevel: 'Advisory',
        vsLevel: 'Light VS (Î™®Îã¨ Ïù∏Ïãù)',
        purpose: 'Î©¥Îã¥ ÌîÑÎ°úÌÜ†ÏΩú, Ïã¨Ìôî ÏßàÎ¨∏ Ï†ÑÎûµ, Ï†ÑÏÇ¨ Í∞ÄÏù¥Îìú Í∞úÎ∞ú',
        triggers: {
          en: ['interview', 'focus group', 'interview protocol', 'semi-structured', 'probing'],
          ko: ['Ïù∏ÌÑ∞Î∑∞', 'Î©¥Îã¥', 'Ìè¨Ïª§Ïä§ Í∑∏Î£π', 'Î∞òÍµ¨Ï°∞Ìôî', 'Ïã¨Ï∏µÎ©¥Îã¥'],
        },
        capabilities: [
          'Î©¥Îã¥ ÌîÑÎ°úÌÜ†ÏΩú Í∞úÎ∞ú (Íµ¨Ï°∞Ìôî, Î∞òÍµ¨Ï°∞Ìôî, ÎπÑÍµ¨Ï°∞Ìôî)',
          'Ìè¨Ïª§Ïä§ Í∑∏Î£π ÏßÑÌñâ Í∞ÄÏù¥Îìú',
          'Ïã¨Ìôî ÏßàÎ¨∏ Î∞è ÌõÑÏÜç ÏßàÎ¨∏ Ï†ÑÎûµ',
          'Ï†ÑÏÇ¨ ÌîÑÎ°úÌÜ†ÏΩú (Ï∂ïÏñ¥Ï†Å, ÏßÄÎä•Ìòï Ï∂ïÏñ¥Ï†Å)',
          'Î©§Î≤Ñ Ï≤¥ÌÇπ Ï†àÏ∞®',
        ],
        vsProcess: 'Ìå®Îü¨Îã§ÏûÑ(ÌòÑÏÉÅÌïô, Í∑ºÍ±∞Ïù¥Î°† Îì±)Ïóê Îî∞Îùº ÌîÑÎ°úÌÜ†ÏΩú Î≥ÄÌòï Ï†úÏïà',
        example: {
          input: '"ÍµêÏÇ¨Ïùò AI Í≤ΩÌóòÏóê ÎåÄÌïú Î©¥Îã¥ ÌîÑÎ°úÌÜ†ÏΩú"',
          output: 'ÎèÑÏûÖ: "AI ÎèÑÍµ¨Î•º Ï≤òÏùå Ï†ëÌñàÏùÑ ÎïåÎ•º Ïù¥ÏïºÍ∏∞Ìï¥ Ï£ºÏÑ∏Ïöî" | Î≥∏Î°†: "AIÍ∞Ä ÏàòÏóÖ Ïã§Ï≤úÏùÑ Î∞îÍæº ÏàúÍ∞ÑÏùÑ ÏÑ§Î™ÖÌï¥ Ï£ºÏÑ∏Ïöî" | Ïã¨Ìôî: "Í∑∏Îïå Ïñ¥Îñ§ ÎäêÎÇåÏù¥ÏóàÎÇòÏöî?" "Í∑∏ Îã§ÏùåÏóî Î¨¥Ïä® ÏùºÏù¥?" | ÎßàÎ¨¥Î¶¨: "Ï†úÍ∞Ä Î¨ªÏßÄ ÏïäÏïòÏßÄÎßå Ï§ëÏöîÌïòÎã§Í≥† ÏÉùÍ∞ÅÌïòÎäî Í≤ÉÏù¥ ÏûàÎÇòÏöî?"',
        },
      },
      {
        id: 'D3',
        name: 'Í¥ÄÏ∞∞ ÌîÑÎ°úÌÜ†ÏΩú ÏÑ§Í≥ÑÏûê',
        icon: 'eye',
        color: '#7d3c98',
        model: 'Haiku',
        tier: 'LOW',
        checkpoint: 'None',
        checkpointLevel: 'Advisory',
        vsLevel: 'None',
        purpose: 'Íµ¨Ï°∞ÌôîÎêú Í¥ÄÏ∞∞ ÌîÑÎ°úÌÜ†ÏΩú, ÌòÑÏû•ÎÖ∏Ìä∏, ÎπÑÎîîÏò§ Î∂ÑÏÑù ÏΩîÎî© Ï≤¥Í≥Ñ ÏÑ§Í≥Ñ',
        triggers: {
          en: ['observation', 'field notes', 'participant observation', 'video analysis', 'ethnography'],
          ko: ['Í¥ÄÏ∞∞', 'ÌòÑÏû•ÎÖ∏Ìä∏', 'Ï∞∏Ïó¨Í¥ÄÏ∞∞', 'ÎπÑÎîîÏò§ Î∂ÑÏÑù', 'ÎØºÏ°±ÏßÄ'],
        },
        capabilities: [
          'ÏΩîÎî© Ï≤¥Í≥ÑÎ•º Í∞ñÏ∂ò Íµ¨Ï°∞ÌôîÎêú Í¥ÄÏ∞∞ ÌîÑÎ°úÌÜ†ÏΩú',
          'ÌòÑÏû•ÎÖ∏Ìä∏ ÌÖúÌîåÎ¶ø (Í∏∞Ïà†Ï†Å, ÏÑ±Ï∞∞Ï†Å, Î∂ÑÏÑùÏ†Å)',
          'ÎπÑÎîîÏò§ Î∂ÑÏÑù ÌîÑÎ†àÏûÑÏõåÌÅ¨ (ÏÉÅÌò∏ÏûëÏö© Î∂ÑÏÑù, ÎåÄÌôî Î∂ÑÏÑù)',
          'Í¥ÄÏ∞∞Ïûê ÌõàÎ†® Ï†àÏ∞®',
          'ÌèâÍ∞ÄÏûê Í∞Ñ Ïã†Î¢∞ÎèÑ ÌîÑÎ°úÌÜ†ÏΩú',
        ],
        vsProcess: 'Ïó∞Íµ¨ Îß•ÎùΩÏóê Í∏∞Î∞òÌïú ÏßÅÏ†ë ÌîÑÎ°úÌÜ†ÏΩú ÏÉùÏÑ±',
        example: {
          input: '"ÍµêÏã§ÏóêÏÑú AI ÎèÑÍµ¨ ÏÇ¨Ïö© Í¥ÄÏ∞∞"',
          output: 'ÏãúÍ∞Ñ ÌëúÏßë: 5Î∂Ñ Í∞ÑÍ≤© | Î≤îÏ£º: ÎèÑÍµ¨ Ïú†Ìòï, Í≥ºÏ†ú Ïú†Ìòï, ÌïôÏÉù Ï∞∏Ïó¨, ÍµêÏÇ¨ ÏßÄÏõê | ÌòÑÏû•ÎÖ∏Ìä∏: Í∏∞Ïà†Ï†Å(Î¨¥Ïä® ÏùºÏù¥ ÏùºÏñ¥ÎÇ¨ÎäîÏßÄ), ÏÑ±Ï∞∞Ï†Å(Í¥ÄÏ∞∞Ïûê ÏÉùÍ∞Å), Î∂ÑÏÑùÏ†Å(Ìå®ÌÑ¥, Ï£ºÏ†ú)',
        },
      },
      {
        id: 'D4',
        name: 'Ï∏°Ï†ïÎèÑÍµ¨ Í∞úÎ∞úÏûê',
        icon: 'clipboardList',
        color: '#6c3483',
        model: 'Opus',
        tier: 'HIGH',
        checkpoint: 'CP_METHODOLOGY_APPROVAL',
        checkpointLevel: 'REQUIRED',
        vsLevel: 'Enhanced VS 3-Phase',
        purpose: 'Ï≤ôÎèÑ Íµ¨ÏÑ±, ÎèÑÍµ¨ ÌÉÄÎãπÌôî, Ïã†Î¢∞ÎèÑ/ÌÉÄÎãπÎèÑ Ï¶ùÍ±∞ Ï†úÍ≥µ',
        triggers: {
          en: ['instrument', 'scale development', 'measurement', 'validity', 'reliability', 'Likert scale'],
          ko: ['Ï∏°Ï†ïÎèÑÍµ¨', 'Ï≤ôÎèÑ Í∞úÎ∞ú', 'ÎèÑÍµ¨ ÌÉÄÎãπÌôî', 'Ïã†Î¢∞ÎèÑ', 'ÌÉÄÎãπÎèÑ', 'Î¶¨Ïª§Ìä∏'],
        },
        capabilities: [
          'Ï≤ôÎèÑ Íµ¨ÏÑ± (Î¨∏Ìï≠ ÏÉùÏÑ±, ÏùëÎãµ ÌòïÏãù)',
          'ÎÇ¥Ïö© ÌÉÄÎãπÎèÑ (Ï†ÑÎ¨∏Í∞Ä Í≤ÄÌÜ†, CVI Í≥ÑÏÇ∞)',
          'Íµ¨ÏÑ± ÌÉÄÎãπÎèÑ (EFA, CFA, ÏïåÎ†§ÏßÑ ÏßëÎã®)',
          'Ïã†Î¢∞ÎèÑ Í≤ÄÏÇ¨ (Cronbach Œ±, Í≤ÄÏÇ¨-Ïû¨Í≤ÄÏÇ¨, ÌèâÍ∞ÄÏûê Í∞Ñ)',
          'Ï∏°Ï†ï Î∂àÎ≥ÄÏÑ± Í≤ÄÏÇ¨',
        ],
        vsProcess: '1Îã®Í≥Ñ: Î™®Îã¨ Ï≤ôÎèÑ ÏãùÎ≥Ñ | 2Îã®Í≥Ñ: Ï†ÅÏùë vs. Ïã†Í∑ú Ï≤ôÎèÑ ÏòµÏÖò Ï†úÏãú | 3Îã®Í≥Ñ: Ïù∏Í∞Ñ Í≤∞Ï†ï',
        example: {
          input: '"ÍµêÏÇ¨Ïùò AI ÏûêÍ∏∞Ìö®Îä•Í∞ê Ï∏°Ï†ï"',
          output: 'üî¥ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏: CP_METHODOLOGY_APPROVAL | ÏòµÏÖò A: Ïª¥Ìì®ÌÑ∞ ÏûêÍ∏∞Ìö®Îä•Í∞ê Ï≤ôÎèÑ Ï†ÅÏùë | ÏòµÏÖò B: Ïã†Í∑ú AI-ÍµêÏàò ÏûêÍ∏∞Ìö®Îä•Í∞ê Ï≤ôÎèÑ (5Í∞ú Ï∞®Ïõê: Í∏∞Ïà†Ï†Å, ÍµêÏú°ÌïôÏ†Å, Ïú§Î¶¨Ï†Å, ÌèâÍ∞Ä, Ï†ÑÎ¨∏ÏÑ±) | ÌÉÄÎãπÌôî: ÎÇ¥Ïö©(Ï†ÑÎ¨∏Í∞Ä 10Î™Ö), Íµ¨ÏÑ±(EFA‚ÜíCFA), Ïã†Î¢∞ÎèÑ(Œ±, Í≤ÄÏÇ¨-Ïû¨Í≤ÄÏÇ¨)',
        },
      },
    ],

    paradigmCoverage: 'Ìå®Îü¨Îã§ÏûÑ Ï†ÅÏö© Î≤îÏúÑ',
    paradigmText: 'ÏñëÏ†Å (D1, D4), ÏßàÏ†Å (D2, D3), ÌòºÌï© (Î™®Îì† ÏóêÏù¥Ï†ÑÌä∏ Ï†ÅÏùë)',

    integrationTitle: 'Îã§Î•∏ Ïπ¥ÌÖåÍ≥†Î¶¨ÏôÄÏùò ÌÜµÌï©',
    integrationPoints: [
      'Ïπ¥ÌÖåÍ≥†Î¶¨ C (ÏÑ§Í≥Ñ): D1ÏùÄ C1/C2/C3 Ïó∞Íµ¨ÏÑ§Í≥ÑÏóê ÏùòÌï¥ Ï†ïÎ≥¥ Ï†úÍ≥µ',
      'Ïπ¥ÌÖåÍ≥†Î¶¨ E (Î∂ÑÏÑù): D4 ÌÉÄÎãπÎèÑ Ï¶ùÍ±∞Í∞Ä E1 ÌÜµÍ≥Ñ Î∂ÑÏÑùÏóê ÌîºÎìú',
      'Ïπ¥ÌÖåÍ≥†Î¶¨ F (ÌíàÏßà): D2/D3 ÌîÑÎ°úÌÜ†ÏΩúÏùÄ F4Ïóê ÏùòÌï¥ Ïã†Î¢∞ÏÑ± Í≤ÄÌÜ†',
      'Ïπ¥ÌÖåÍ≥†Î¶¨ A (Í∏∞Ï¥à): D4 ÎèÑÍµ¨Í∞Ä A2 Ïù¥Î°†Ï†Å ÌîÑÎ†àÏûÑÏõåÌÅ¨ÏôÄ Ï†ïÎ†¨',
    ],

    checkpointInfo: 'Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ïÎ≥¥',
    checkpointText: 'D4 (Ï∏°Ï†ïÎèÑÍµ¨ Í∞úÎ∞úÏûê)Îäî Ïó∞Íµ¨ ÏÑ§Í≥Ñ Î∞è Ïù¥Î°†Ï†Å ÌîÑÎ†àÏûÑÏõåÌÅ¨ÏôÄÏùò Ï†ïÎ†¨ÏùÑ Î≥¥Ïû•ÌïòÍ∏∞ ÏúÑÌï¥ Ï≤ôÎèÑ Íµ¨ÏÑ± Ï†ÑÏóê CP_METHODOLOGY_APPROVAL (üî¥ ÌïÑÏàò)Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.',

    bestPractices: 'Î™®Î≤î ÏÇ¨Î°Ä',
    practices: [
      'ÌëúÎ≥∏ ÌÅ¨Í∏∞ Ï†ïÎãπÌôî: Ìï≠ÏÉÅ Í≤ÄÏ†ïÎ†• Î∂ÑÏÑù(ÏñëÏ†Å) ÎòêÎäî Ìè¨Ìôî Í∑ºÍ±∞(ÏßàÏ†Å) Ï†úÍ≥µ',
      'ÌîÑÎ°úÌÜ†ÏΩú ÌååÏùºÎüø ÌÖåÏä§Ìä∏: Ï†ÑÏ≤¥ ÏûêÎ£å ÏàòÏßë Ï†Ñ 2-3Î™Ö Ï∞∏Í∞ÄÏûêÏôÄ Î©¥Îã¥/Í¥ÄÏ∞∞ ÌîÑÎ°úÌÜ†ÏΩú ÌÖåÏä§Ìä∏',
      'ÎèÑÍµ¨ ÌÉÄÎãπÌôî: ÏµúÏÜå Ï¶ùÍ±∞ = ÎÇ¥Ïö© ÌÉÄÎãπÎèÑ + ÎÇ¥Ï†Å ÏùºÍ¥ÄÏÑ±',
      'Ïú§Î¶¨Ï†Å Í≥†Î†§ÏÇ¨Ìï≠: D1-D4Í∞Ä Í≤ÄÌÜ†Ìïú Î™®Îì† ÌîÑÎ°úÌÜ†ÏΩúÏùÄ ÎèôÏùò, Í∞úÏù∏Ï†ïÎ≥¥, Îç∞Ïù¥ÌÑ∞ Î≥¥ÏïàÏùÑ Îã§Î§ÑÏïº Ìï®',
    ],

    autoTrigger: 'ÏûêÎèô Ìä∏Î¶¨Í±∞ ÏòàÏãú',
    autoTriggerExamples: [
      {
        userInput: '"AI Ï±ÑÌÉùÏóê ÎåÄÌï¥ 20Î™ÖÏùò ÍµêÏÇ¨Î•º Î©¥Îã¥Ìï¥Ïïº Ìï¥Ïöî"',
        detected: 'ÌÇ§ÏõåÎìú: "Î©¥Îã¥", "20Î™ÖÏùò ÍµêÏÇ¨" ‚Üí D2 (Î©¥Îã¥ Ï†ÑÎ¨∏Í∞Ä) + D1 (ÌëúÏßë) Ìä∏Î¶¨Í±∞',
        execution: 'D2Í∞Ä Î∞òÍµ¨Ï°∞Ìôî ÌîÑÎ°úÌÜ†ÏΩú Í∞úÎ∞ú ‚Üí D1Ïù¥ Î™©Ï†ÅÏ†Å ÌëúÏßë Ï†ÑÎûµ Ï†úÏïà',
      },
      {
        userInput: '"AI Î≥¥Ï°∞ ÌïôÏäµÏóêÏÑú ÌïôÏÉù ÎèôÍ∏∞Î•º Ï∏°Ï†ïÌïòÎäî Ï≤ôÎèÑ ÎßåÎì§Í∏∞"',
        detected: 'ÌÇ§ÏõåÎìú: "Ï≤ôÎèÑ", "Ï∏°Ï†ï" ‚Üí D4 (ÎèÑÍµ¨ Í∞úÎ∞úÏûê) Ìä∏Î¶¨Í±∞',
        execution: 'üî¥ CP_METHODOLOGY_APPROVAL ‚Üí D4Í∞Ä Ï†úÏãú: Í∏∞Ï°¥ Ï≤ôÎèÑ Ï†ÅÏùë(AMS) vs. Ïã†Í∑ú Ï≤ôÎèÑ ‚Üí Ïù∏Í∞Ñ Í≤∞Ï†ï',
      },
    ],
  },
};

const iconMap = {
  users: Users,
  messageSquare: MessageSquare,
  eye: Eye,
  clipboardList: ClipboardList,
  alertCircle: AlertCircle,
  checkCircle2: CheckCircle2,
  clock: Clock,
};

export default function CollectionAgentsPage() {
  const locale = useLocale() as 'en' | 'ko';
  const t = content[locale];

  return (
    <div className="min-h-screen bg-void-black text-void-white">
      <div className="max-w-7xl mx-auto px-6 py-12">
        {/* Back button */}
        <Link
          href={`/${locale}/docs/agents`}
          className="inline-flex items-center gap-2 text-void-gray-400 hover:text-void-white transition-colors mb-8"
        >
          <ArrowLeft className="w-4 h-4" />
          {t.back}
        </Link>

        {/* Header */}
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={{ opacity: 1, y: 0 }}
          className="mb-12"
        >
          <div className="inline-block px-3 py-1 bg-[#9b59b6]/20 text-[#9b59b6] rounded-full text-sm mb-4">
            Category D
          </div>
          <h1 className="text-4xl font-bold mb-4">{t.title}</h1>
          <p className="text-xl text-void-gray-400 mb-6">{t.subtitle}</p>
          <p className="text-void-gray-300 leading-relaxed">{t.description}</p>
        </motion.div>

        {/* Core Principle */}
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={{ opacity: 1, y: 0 }}
          transition={{ delay: 0.1 }}
          className="bg-void-gray-900 border border-void-gray-800 rounded-lg p-6 mb-12"
        >
          <h2 className="text-xl font-semibold mb-3 flex items-center gap-2">
            <AlertCircle className="w-5 h-5 text-[#9b59b6]" />
            {t.principleTitle}
          </h2>
          <p className="text-void-gray-300">{t.principleText}</p>
        </motion.div>

        {/* Agents */}
        <div className="space-y-8 mb-12">
          {t.agents.map((agent, index) => {
            const Icon = iconMap[agent.icon as keyof typeof iconMap];
            return (
              <motion.div
                key={agent.id}
                initial={{ opacity: 0, y: 20 }}
                animate={{ opacity: 1, y: 0 }}
                transition={{ delay: 0.2 + index * 0.1 }}
                className="bg-void-gray-900 border border-void-gray-800 rounded-lg overflow-hidden hover:border-[#9b59b6]/50 transition-colors"
              >
                {/* Agent header */}
                <div className="p-6 border-b border-void-gray-800">
                  <div className="flex items-start gap-4">
                    <div
                      className="w-12 h-12 rounded-lg flex items-center justify-center flex-shrink-0"
                      style={{ backgroundColor: `${agent.color}20` }}
                    >
                      <Icon className="w-6 h-6" style={{ color: agent.color }} />
                    </div>
                    <div className="flex-1">
                      <div className="flex items-center gap-3 mb-2">
                        <h3 className="text-2xl font-semibold">{agent.name}</h3>
                        <span className="px-2 py-1 bg-void-gray-800 text-void-gray-400 rounded text-xs">
                          {agent.id}
                        </span>
                      </div>
                      <p className="text-void-gray-300 mb-4">{agent.purpose}</p>
                      <div className="flex flex-wrap gap-2">
                        <span className="px-3 py-1 bg-blue-500/20 text-blue-400 rounded-full text-sm">
                          {agent.model}
                        </span>
                        <span className="px-3 py-1 bg-purple-500/20 text-purple-400 rounded-full text-sm">
                          {agent.tier}
                        </span>
                        {agent.checkpoint !== 'None' && (
                          <span className="px-3 py-1 bg-red-500/20 text-red-400 rounded-full text-sm">
                            üî¥ {agent.checkpoint}
                          </span>
                        )}
                        <span className="px-3 py-1 bg-void-gray-800 text-void-gray-400 rounded-full text-sm">
                          {agent.vsLevel}
                        </span>
                      </div>
                    </div>
                  </div>
                </div>

                {/* Agent details */}
                <div className="p-6 space-y-4">
                  {/* Triggers */}
                  <div>
                    <h4 className="text-sm font-semibold text-void-gray-400 mb-2">
                      {locale === 'en' ? 'Trigger Keywords' : 'Ìä∏Î¶¨Í±∞ ÌÇ§ÏõåÎìú'}
                    </h4>
                    <div className="flex flex-wrap gap-2">
                      {agent.triggers.en.map((trigger, i) => (
                        <span
                          key={i}
                          className="px-2 py-1 bg-void-gray-800 text-void-gray-300 rounded text-sm"
                        >
                          {trigger}
                        </span>
                      ))}
                    </div>
                  </div>

                  {/* Capabilities */}
                  <div>
                    <h4 className="text-sm font-semibold text-void-gray-400 mb-2">
                      {locale === 'en' ? 'Capabilities' : 'Í∏∞Îä•'}
                    </h4>
                    <ul className="space-y-1">
                      {agent.capabilities.map((cap, i) => (
                        <li key={i} className="text-void-gray-300 text-sm flex items-start gap-2">
                          <CheckCircle2 className="w-4 h-4 text-[#9b59b6] mt-0.5 flex-shrink-0" />
                          <span>{cap}</span>
                        </li>
                      ))}
                    </ul>
                  </div>

                  {/* VS Process */}
                  <div>
                    <h4 className="text-sm font-semibold text-void-gray-400 mb-2">
                      {locale === 'en' ? 'VS Process' : 'VS ÌîÑÎ°úÏÑ∏Ïä§'}
                    </h4>
                    <p className="text-void-gray-300 text-sm">{agent.vsProcess}</p>
                  </div>

                  {/* Example */}
                  <div className="bg-void-gray-950 rounded p-4">
                    <h4 className="text-sm font-semibold text-void-gray-400 mb-2">
                      {locale === 'en' ? 'Example' : 'ÏòàÏãú'}
                    </h4>
                    <div className="space-y-2 text-sm">
                      <div>
                        <span className="text-void-gray-500">Input:</span>{' '}
                        <span className="text-void-gray-300">{agent.example.input}</span>
                      </div>
                      <div>
                        <span className="text-void-gray-500">Output:</span>{' '}
                        <span className="text-void-gray-300">{agent.example.output}</span>
                      </div>
                    </div>
                  </div>
                </div>
              </motion.div>
            );
          })}
        </div>

        {/* Paradigm Coverage */}
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={{ opacity: 1, y: 0 }}
          transition={{ delay: 0.6 }}
          className="bg-void-gray-900 border border-void-gray-800 rounded-lg p-6 mb-8"
        >
          <h2 className="text-xl font-semibold mb-3">{t.paradigmCoverage}</h2>
          <p className="text-void-gray-300">{t.paradigmText}</p>
        </motion.div>

        {/* Integration */}
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={{ opacity: 1, y: 0 }}
          transition={{ delay: 0.7 }}
          className="bg-void-gray-900 border border-void-gray-800 rounded-lg p-6 mb-8"
        >
          <h2 className="text-xl font-semibold mb-4">{t.integrationTitle}</h2>
          <ul className="space-y-2">
            {t.integrationPoints.map((point, i) => (
              <li key={i} className="text-void-gray-300 text-sm flex items-start gap-2">
                <CheckCircle2 className="w-4 h-4 text-[#9b59b6] mt-0.5 flex-shrink-0" />
                <span>{point}</span>
              </li>
            ))}
          </ul>
        </motion.div>

        {/* Checkpoint Info */}
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={{ opacity: 1, y: 0 }}
          transition={{ delay: 0.8 }}
          className="bg-red-500/10 border border-red-500/30 rounded-lg p-6 mb-8"
        >
          <h2 className="text-xl font-semibold mb-3 flex items-center gap-2">
            <AlertCircle className="w-5 h-5 text-red-400" />
            {t.checkpointInfo}
          </h2>
          <p className="text-void-gray-300">{t.checkpointText}</p>
        </motion.div>

        {/* Best Practices */}
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={{ opacity: 1, y: 0 }}
          transition={{ delay: 0.9 }}
          className="bg-void-gray-900 border border-void-gray-800 rounded-lg p-6 mb-8"
        >
          <h2 className="text-xl font-semibold mb-4">{t.bestPractices}</h2>
          <ul className="space-y-2">
            {t.practices.map((practice, i) => (
              <li key={i} className="text-void-gray-300 text-sm flex items-start gap-2">
                <CheckCircle2 className="w-4 h-4 text-[#9b59b6] mt-0.5 flex-shrink-0" />
                <span>{practice}</span>
              </li>
            ))}
          </ul>
        </motion.div>

        {/* Auto-Trigger Examples */}
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={{ opacity: 1, y: 0 }}
          transition={{ delay: 1.0 }}
          className="bg-void-gray-900 border border-void-gray-800 rounded-lg p-6"
        >
          <h2 className="text-xl font-semibold mb-4">{t.autoTrigger}</h2>
          <div className="space-y-4">
            {t.autoTriggerExamples.map((example, i) => (
              <div key={i} className="bg-void-gray-950 rounded p-4">
                <div className="space-y-2 text-sm">
                  <div>
                    <span className="text-void-gray-500">
                      {locale === 'en' ? 'User Input:' : 'ÏÇ¨Ïö©Ïûê ÏûÖÎ†•:'}
                    </span>{' '}
                    <span className="text-void-gray-300">{example.userInput}</span>
                  </div>
                  <div>
                    <span className="text-void-gray-500">
                      {locale === 'en' ? 'Detected:' : 'Í∞êÏßÄÎê®:'}
                    </span>{' '}
                    <span className="text-yellow-400">{example.detected}</span>
                  </div>
                  <div>
                    <span className="text-void-gray-500">
                      {locale === 'en' ? 'Execution:' : 'Ïã§Ìñâ:'}
                    </span>{' '}
                    <span className="text-void-gray-300">{example.execution}</span>
                  </div>
                </div>
              </div>
            ))}
          </div>
        </motion.div>
      </div>
    </div>
  );
}
